\section{Application: \\
Revealing ISP Behavior}
\label{sec:isp-behavior}

This section describes how we build two applications atop \meddle to 
reveal the policies ISPs apply to mobile traffic traversing their networks. 
Previous work focused on addressing this problem in fixed-line networks; to 
the best of our knowledge we are the first to provide this functionality for 
mobile systems.

\subsection{Web Tripnets: Detecting ISP Content Manipulation}

ISPs, middleboxes and client software are known to change Web page content for 
a variety of reasons including performance optimization and security. In some cases, 
a third party can change a page for selfish reasons, \eg to insert ads that generate revenue 
for that party. Figure~\ref{fig:tripnet-example} depicts an example of content injection in China, where 
a banner ad is replaced by information about the local airport.

\begin{figure}
\centering
\includegraphics[width=0.9\linewidth]{figures/injectioncrop.png}
\caption{Screen capture of content injection by a Chinese ISP in November, 2013. The 
highlighted region at the bottom should be an advertisement from a US company. }
\vspace{\postfigspace}
\label{fig:tripnet-example}
\end{figure}


This problem of Web interference was first highlighted by Reis~\etal~\cite{reis:tripwires}. 
The authors demonstrated that although a small percent of users were affected by in-flight changes, those changes tend to introduce vulnerabilities including cross-site scripting (XSS) attacks. 
They proposed and deployed \emph{Web Tripwires}, Javascript code to detect in-flight page changes. 
The main limitation of \emph{Web Tripwires} is that it requires each Web site to modify their content to include a tripwire.

In \meddle, we extended tripwires to alleviate this limitation. 
Namely, we use the HTTP proxy present in \meddle to inject a tripwire on \emph{any} page 
without requiring support from Web site developers -- an approach we call a \emph{Web Tripnet}.

\noindent\textbf{Implementation.} With \meddle all traffic is tunneled, thereby 
preventing ISPs from modifying pages. To help inform non-users of ISP content 
manipulation, we provide the Tripnet as an opt-in feature. Because this entails 
two fetches of every Web page, we also support two modes: always-on and low-rate random trials, where we 
insert tripwires for some small fraction of their visited sites.

The Tripnet works as follows (Fig.~\ref{fig:tripnet}). A client requests a Web page through the \meddle VPN 
tunnel. This request is forwarded to the destination server. The response returns to 
the \meddle server, where a transparent proxy injects the tripwire code.\footnote{We 
recognize the irony of injecting content to detect content injection, but this is done only with user consent.}
The tripwire-enabled response is forwarded to the client, which execute the javascript at page load time.


\begin{figure}
\centering
\includegraphics[width=0.9\linewidth]{figures/tripnet.pdf}
\caption{Overview of the Web Tripnet. A Web page loads 
through the VPN tunnel, where a meddlebox inserts a Web tripwire. The
tripwire causes the browser to reload the Web page using the address of a
transparent proxy server that is accessed using an unencrypted connection.
After the proxied version of the page is loaded, the browser (or a meddlebox)
compare the two pages to identify manipulation. }
\label{fig:tripnet}
\vspace{\postfigspace}
\end{figure}

The tripwire code contains information about the page content prior to traversing the ISP. When 
executed, the code fetches the page again to compare with the (known) unmodified page content.  
To ensure that this fetch does \emph{not} traverse the VPN connection, we use a \emph{pigeonhole} domain 
whose traffic traverses an untunneled interface. For example, if the original request was for \url{www.facebook.com}, 
we send the request to \url{tripnet.meddle.mobi/www.facebook.com}, where we run a Web proxy. 

When the request arrives at our proxy server, we could forward the request to the original target. In 
practice, however, doing so would return different content due to the highly dynamic nature of most 
Web content. Instead, we cache Web pages at the tripnet-injecting server and co-locate our Web proxy 
there. Thus we return exactly the same Web page that was received over the tunneled connection. 
Any difference in page content can only be due to ISP behavior. 

In addition to detecting changes to text content in 
Web pages, we use our controlled experiments to investigate whether ISPs are manipulating 
media content, \eg downsampling high-resolution images to reduce bandwidth consumption 
from mobile devices. For this experiment, we augment our Tripnet experiments with the result 
of wget results from the mobile device and the proxy server. Note that this experiment requires an 
app or tethered laptop to collect the Web media objects fetched over the mobile network.

\noindent\textbf{Sites and ISPs tested.} We conducted controlled experiments using our Tripnet 
architecture, using the top 100 Web sites according to Alexa. We tested using 
AT\&T, T-Mobile and Verizon in the US, and Orange, Sosh and Bouygues in France. 
Many sites customize content according to User-Agent strings, so we spoof User-Agents 
as coming from iOS, Andriod and desktop clients.

\noindent\textbf{Content modification/injection.} We found no cases of page modifications in 
the networks tested. In addition the example in Fig.~\ref{fig:tripnet-example}, we found whole-page replacement in the case of T-Mobile. A 
service called \emph{Web Guard} replaced the page for an adult Web site with a block page. 
Further, our tests allowed us to identify differences in Web content not due an ISP. Specifically, 
we observe that Wordpress hosts a jquery.js file using the Edgecast CDN, and the file contents 
differ depending on where the client is located. When accessed directly from mobile devices the 
script size is 256\,KB; when accessed from the proxy server the script is 93\,KB. The difference in 
size is because the latter uses a minified version of the script; it is unclear why this is not served 
to all the networks.

\subsection{Mobile Replay: Detecting Service Differentiation}

In this section, we describe how we use \meddle to detect service differentiation 
in ISPs. To the best of our knowledge, this is the first system to provide such information 
in mobile systems.

We define service differentiation as any attempt to change the performance 
of network traffic traversing an ISP's boundaries. ISPs may implement differentiation policies 
for a number of reasons, including load balancing, bandwidth management or business reasons. 
Specifically, we focus on detecting whether certain types of network traffic receive 
better (or worse) performance. 

Previous work~\cite{dischinger:glasnost,tariq:nano,zhang:netdiff} explored this problem in limited 
environments. Glasnost focused on BitTorrent in the desktop/laptop environment, 
and lacked the ability to conduct controlled experiments to provide strong evidence 
of differentiation. NetDiff covered a wide range of passively gathered traffic from a 
large ISP but likewise did not support targeted, controlled experiments. We now 
describe how we address these limitations with \emph{Mobile Replay}. 

\noindent\textbf{Assumptions.} We assume that ISPs will differentiate traffic based on hostname, 
IP addresses, ports, total number of connections, payload signatures, total bandwidth and time of day. 
Our system can diagnose nearly all of these cases. 

\noindent\textbf{Overview.} Mobile Replay identifies service differentiation using 
two key components. First, it tests for differentiation by replaying real network traces 
generated from user interactions with apps. \meddle facilitates capturing this information, 
and we develop new strategies for replaying arbitrary app traces. Second, Mobile 
Replay exploits the \meddle VPN to conduct controlled experiments. By alternately replaying 
traffic over tunneled and untunneled connections multiple times in rapid succession to control 
for factors that ISPs may use to differentiate traffic.

One key challenge is what traffic to use to detect differentiation. The challenge is how to capture and replay 
the salient features of application traffic such that it will be subject to differentiation 
from middleboxes. To this end, we design a system that captures 
traffic naturally generated by users' devices (via \meddle) and replays those flows 
with high fidelity from a \emph{replay server}. 

The replay system consists of a client running on the mobile device and a replay server. 
The client and server coordinate to replay the original flows in a way that reproduces packet timings, 
sequence of bytes, ports and source IPs. When the destination of the original traffic is neither the 
mobile device nor the replay server IP, we must change the destination IP. Thus, we cannot detect 
differentiation based on destination IP. \drc{Add UDP challenges?}

Another key challenge is how to establish ground truth as to whether the ISP is 
actually differentiating service for replay traffic. To address this, we exploit the fact 
that \meddle already gives participating users access to a VPN connection. When the 
VPN is enabled, the ISP cannot inspect flow contents and thus cannot differentiate based 
on all of the above factors except total bandwidth and time of day. This tells us what 
performance flows receive when the ISP can only infer that there is a VPN tunnel. 
We then compare this performance to the case when we send traffic untunneled through a 
pigeonhole. Using multiple successive trials of tunneled and untunneled replay experiments, 
we can determine the inherent noise in performance metrics in each category, then 
identify cases where there are statistically significant differences in performance between 
them -- indicating differentiation. 

%Overview of the approach and challenges. \meddle allows us to capture 
%traces from mobile devices over both \wifi and cell, meaning we can model 
%behavior from either medium. \meddle also serves as a convenient location 
%to conduct replay experiments. The challenge is how to capture and replay 
%the salient features of application traffic such that it will be subject to differentiation 
%from middleboxes. State what we can reproduce (timings, sequence of bytes, ports and source IPs) 
%and what we cannot (destination IPs from client). Challenges with UDP. Challenges 
%with different network conditions. Differences from Glasnost.




\noindent\textbf{Approach and feasibility.}
Figure~\ref{fig:replaySimilarity} uses a sequence-number diagram to compare the behavior of original traces 
to those generated by our replay system. By preserving packet ordering and timing, our 
system produces very similar results. 

\begin{figure}
\centering
\includegraphics[width=0.9\linewidth]{plots/netflix_seqnum_wifi_vs_cell.pdf}
\caption{Plot of record (solid) and and replay (dashed) from Netflix activity. The x-axis is time and y-axis is the 
total number of bytes transferred to that point. The figure shows that our replay closely matches 
the recorded trace.}
\vspace{\postfigspace}
\label{fig:replaySimilarity}
\end{figure}

Of course, a variety of factors can differ between record and replay, including network 
conditions and access technology. In particular, apps may change their behavior in response 
to different network reliability and available bandwidth. For example, the YouTube app does not 
allow HD video content over cellular networks. In such cases, we must ensure that we replay 
traffic that was originally captured over the same network conditions and access technology. 
In our experiments, YouTube was the only app that exhibited such behavior.


\textbf{Graph}: If we find a case of difference between \wifi and cell, plot it here.



\noindent\textbf{Methodology.} We detect differentiation according to the following metrics. First, we 
compute checksums to verify that the bytes sent/received at each endpoint during the replay are 
exactly the same as the original trace. If not, we flag a case of content manipulation/blocking. Second, we
compute summary statistics on throughput, latency and loss. Unlike manipulation/blocking, there are 
confounding factors other than differentiation that may causes changes in these statistics between the 
record and replay.

To address this issue, we run multiple trials of replay (X total), alternating between using a VPN connection ($R_T$) and 
a plain (untunneled) one ($R_U$). By computing statistics over multiple trials of one category ($R_T$ or $R_U$) we 
can control for whether the ISP can differentiate and assign the variance in these trials as being due to 
any number of other confounding factors. Having computed the variance over $R_T$ and $R_U$, we can 
compare the summary statistics (mean/median) of $R_T$ and $R_U$ and use the variance in each category 
to determine if the differences are statistically significant.

Note that ISPs may apply differentiation to all VPN traffic, \eg by throttling. To detect this, we group all $R_T$ 
samples and compare them to all $R_U$ samples across all applications and use the analysis described above. 

\textbf{Graph}: Similarity score for network traffic in setting where we know there is no differentiation. 
Score can include overall throughput, latency characteristics, loss, packet timings.

\noindent\textbf{Results from wide-area testing.} We used Mobile Replay to investigate service differentiation in 
ISPs A, B, C, \tbd{Figure this out.} using the following representative apps: \tbd{insert names and why}. 
 
Networks tested, observed behavior.

\textbf{Table}: each row is an app, each column is an ISP, each cell is a marker indicating what kind of 
differentiation is happening

\textbf{Graph}: Plot showing a sequence of traces that demonstrates what this differentiation looks like


\noindent\textbf{Implications.}  TBD 

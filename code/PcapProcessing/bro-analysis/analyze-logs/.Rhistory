overHeadsDir="/Users/ashwin/proj-work/meddle/meddle-data/overheads"
fName<-paste(overHeadsDir,"/bytes-ethernet",sep="");
ethernetBytes <- read.table(fName, header=FALSE, quote="");
ethernetBytes <- cumsum(as.numeric(ethernetBytes[,1]))
ethernetBytes <- ethernetBytes[order(ethernetBytes)]
fName<-paste(overHeadsDir,"/bytes-tunnel",sep="");
tunnelBytes <- read.table(fName, header=FALSE, quote="");
tunnelBytes <- cumsum(as.numeric(tunnelBytes[,1]))
tunnelBytes <- tunnelBytes[order(tunnelBytes)]
sampleLength <- min(length(ethernetBytes), length(tunnelBytes))
overheads <- ethernetBytes[1:sampleLength]/tunnelBytes[1:sampleLength]
overheads[is.na(overheads)] <- -1;
overheads <- overheads[overheads>=0];
pdf(paste(overHeadsDir,"/overheads.pdf",sep=""))
plot(ecdf(overheads))
dev.off()
baseDir<-"/Users/ashwin/proj-work/meddle/meddle-data/"
scriptsDir<-"/Users/ashwin/proj-work/meddle/ashwin-meddle/meddle/code/PcapProcessing/bro-analysis/analyze-logs/"
setwd(scriptsDir);
broAggDir<-paste(baseDir,"bro-aggregate-data/", sep="");
broLogsDir<-paste(baseDir, "bro-results/", sep="");
plotsDir=paste(baseDir, "plots/", sep="");
opar = par();
newpar = par(cex.lab=1.25, cex.axis=1.25, cex.main=1.25, cex.sub=1.25, cex=1.25, xaxs="i", yaxs="i",lwd=3);
fName <- paste(broAggDir, "/conn.log.an", sep="");
connData <- read.table(fName, header=T, sep="\t", fill=TRUE, stringsAsFactors=FALSE, quote="");
baseDir<-"/Users/ashwin/proj-work/meddle/meddle-data/"
scriptsDir<-"/Users/ashwin/proj-work/meddle/ashwin-meddle/meddle/code/PcapProcessing/bro-analysis/analyze-logs/"
setwd(scriptsDir);
broAggDir<-paste(baseDir,"bro-aggregate-data/", sep="");
broLogsDir<-paste(baseDir, "bro-results/", sep="");
plotsDir=paste(baseDir, "plots/", sep="");
opar = par();
newpar = par(cex.lab=1.25, cex.axis=1.25, cex.main=1.25, cex.sub=1.25, cex=1.25, xaxs="i", yaxs="i",lwd=3);
fName <- paste(broAggDir, "/conn.log.ann", sep="");
connData <- read.table(fName, header=T, sep="\t", fill=TRUE, stringsAsFactors=FALSE, quote="");
baseDir<-"/Users/ashwin/proj-work/meddle/meddle-data/"
scriptsDir<-"/Users/ashwin/proj-work/meddle/ashwin-meddle/meddle/code/PcapProcessing/bro-analysis/analyze-logs/"
setwd(scriptsDir);
broAggDir<-paste(baseDir,"bro-aggregate-data/", sep="");
broLogsDir<-paste(baseDir, "bro-results/", sep="");
plotsDir=paste(baseDir, "plots/", sep="");
opar = par();
newpar = par(cex.lab=1.25, cex.axis=1.25, cex.main=1.25, cex.sub=1.25, cex=1.25, xaxs="i", yaxs="i",lwd=3);
convertStringColsToDouble <- function (stringCol) {
stringCol <- as.double(stringCol)
stringCol[is.na(stringCol)] <-0;
stringCol;
}
getHTTPData <- function() {
fName <- paste(broAggDir, "/http.log.ann", sep="");
if (file.exists(fName) == FALSE) {
print(fName);
return(NA);
}
print("Reading Http")
httpData <- read.table(fName, header=T, sep="\t", fill=TRUE, stringsAsFactors=FALSE, quote=""); # Note FILL causes silent padding
if (nrow(httpData) < 10) {
print(fName);
return(NA);
}
httpData$content_length <- convertStringColsToDouble(httpData$content_length)
httpData$response_body_len <- convertStringColsToDouble(httpData$response_body_len)
httpData$request_body_len <- convertStringColsToDouble(httpData$request_body_len)
httpData$connLen <- httpData$request_body_len + httpData$content_length;
httpData[httpData$technology=="Unknown",]$technology<-"Wi-Fi"
httpData;
}
getTextRows <-function(httpData){
print("Finding Text")
rowIDs <- grep("text", httpData$mime_type);
rowIDs <- append(rowIDs, grep("text", httpData$content_type));
rowIDs <- unique(sort(rowIDs));
textRows <- httpData[rowIDs, ];
textRows;
}
getZipRows <- function(textRows) {
print("Finding Zip")
zipRows <- textRows[grep("zip", textRows$content_encoding), ];
zipRows;
}
getChunkedRows <- function(textRows) {
print("Finding Chunked")
zipRows <- textRows[grep("chunked", textRows$transfer_encoding), ];
zipRows;
}
getUnCompressed <- function(textRows) {
uncomp <- textRows[textRows$content_length == textRows$response_body_len, ]
uncomp;
}
getCompressFailRows <- function(zipRows) {
# find entries with gzip in content_type
print("Finding Compress Fail")
compressFailRows <- zipRows[(zipRows$content_length > zipRows$response_body_len),];
compressFailRows;
}
httpData <- getHTTPData();
textRows <- getTextRows(httpData);
zipRows <- getZipRows(textRows)
chunkRows <- getChunkedRows(textRows)
uncompRows <- getUnCompressed(textRows)
compressFail <- getCompressFailRows(zipRows);
nrow(textRows)/nrow(httpData)
sum(textRows$connLen)/sum(httpData$connLen)
nrow(zipRows)/nrow(textRows)
sum(zipRows$connLen)/sum(textRows$connLen)
nrow(chunkRows)/nrow(textRows)
sum(chunkRows$connLen)/sum(textRows$connLen)
nrow(uncompRows)/nrow(textRows)
sum(uncompRows$connLen)/sum(textRows$connLen)
nrow(uncompRows)/nrow(httpData)
sum(uncompRows$connLen)/sum(httpData$connLen)
nrow(compressFail)/nrow(textRows)
sum(compressFail$content_length)/sum(textRows$content_length)
#Are all users active for at least one 24 hour cycle
baseDir<-"/Users/ashwin/proj-work/meddle/meddle-data/"
scriptsDir<-"/Users/ashwin/proj-work/meddle/ashwin-meddle/meddle/code/PcapProcessing/bro-analysis/analyze-logs/"
setwd(scriptsDir);
broAggDir<-paste(baseDir,"bro-aggregate-data/", sep="");
broLogsDir<-paste(baseDir, "bro-results/", sep="");
plotsDir=paste(baseDir, "plots/", sep="");
opar = par();
newpar = par(cex.lab=1.25, cex.axis=1.25, cex.main=1.25, cex.sub=1.25, cex=1.25, xaxs="i", yaxs="i",lwd=3);
fName <- paste(broAggDir, "/conn.log.ann", sep="");
connData <- read.table(fName, header=T, sep="\t", fill=TRUE, stringsAsFactors=FALSE, quote="");
connData$ts_date <- as.POSIXlt(as.numeric(connData$ts), tz="America/Los_Angeles", origin = "1970-01-01")
connData$yday <- connData$ts_date$yday;
connData$hour <- connData$ts_date$hour;
connAggr <- aggregate(connData[c("orig_bytes")],
by=list(user_id=connData$user_id, yday=connData$yday, hour=connData$hour),
FUN=length);
connHourAggr <- aggregate(connAggr[c("hour")],
by=list(user_id=connAggr$user_id, yday=connAggr$yday),
FUN=length);
viewData(connHourAggr)
connMaxHour <- aggregate(connHourAggr[c("hour")],
by=list(user_id=connHourAggr$user_id, yday=connHourAggr$yday),
FUN=max);
viewData(connMaxHour)
connAggr <- aggregate(connData[c("orig_bytes")],
by=list(user_id=connData$user_id, yday=connData$yday, hour=connData$hour),
FUN=length);
connHourAggr <- aggregate(connAggr[c("hour")],
by=list(user_id=connAggr$user_id, yday=connAggr$yday),
FUN=length);
connMaxHour <- aggregate(connHourAggr[c("hour")],
by=list(user_id=connHourAggr$user_id, yday=connHourAggr$yday),
FUN=max);
viewData(connHourAggr)
connMaxHour <- aggregate(connHourAggr[c("hour")],
by=list(user_id=connHourAggr$user_id, yday=connHourAggr$yday),
FUN=median);
viewData(connHourAggr)
connAggr <- aggregate(connData[c("orig_bytes")],
by=list(user_id=connData$user_id, yday=connData$yday, hour=connData$hour),
FUN=length);
connHourAggr <- aggregate(connAggr[c("hour")],
by=list(user_id=connAggr$user_id, yday=connAggr$yday),
FUN=length);
connMaxHour <- aggregate(connHourAggr[c("hour")],
by=list(user_id=connHourAggr$user_id),
FUN=median);
viewData(connMaxHour)
connMaxHour <- aggregate(connHourAggr[c("hour")],
by=list(user_id=connHourAggr$user_id),
FUN=max);
viewData(connMaxHour)
baseDir<-"/Users/ashwin/proj-work/meddle/meddle-data/"
scriptsDir<-"/Users/ashwin/proj-work/meddle/ashwin-meddle/meddle/code/PcapProcessing/bro-analysis/analyze-logs/"
setwd(scriptsDir);
broAggDir<-paste(baseDir,"bro-aggregate-data/", sep="");
broLogsDir<-paste(baseDir, "bro-results/", sep="");
plotsDir=paste(baseDir, "plots/", sep="");
opar = par();
newpar = par(cex.lab=1.25, cex.axis=1.25, cex.main=1.25, cex.sub=1.25, cex=1.25, xaxs="i", yaxs="i",lwd=3);
convertStringColsToDouble <- function (stringCol) {
stringCol <- as.double(stringCol)
stringCol[is.na(stringCol)] <-0;
stringCol;
}
getHTTPData <- function() {
fName <- paste(broAggDir, "/http.log.ann", sep="");
if (file.exists(fName) == FALSE) {
print(fName);
return(NA);
}
print("Reading Http")
httpData <- read.table(fName, header=T, sep="\t", fill=TRUE, stringsAsFactors=FALSE, quote=""); # Note FILL causes silent padding
if (nrow(httpData) < 10) {
print(fName);
return(NA);
}
httpData$content_length <- convertStringColsToDouble(httpData$content_length)
httpData$response_body_len <- convertStringColsToDouble(httpData$response_body_len)
httpData$request_body_len <- convertStringColsToDouble(httpData$request_body_len)
httpData$connLen <- httpData$request_body_len + httpData$content_length;
httpData[httpData$technology=="Unknown",]$technology<-"Wi-Fi"
httpData;
}
getTextRows <-function(httpData){
print("Finding Text")
rowIDs <- grep("text", httpData$mime_type);
rowIDs <- append(rowIDs, grep("text", httpData$content_type));
rowIDs <- unique(sort(rowIDs));
textRows <- httpData[rowIDs, ];
textRows;
}
getZipRows <- function(textRows) {
print("Finding Zip")
zipRows <- textRows[grep("zip", textRows$content_encoding), ];
zipRows;
}
getChunkedRows <- function(textRows) {
print("Finding Chunked")
zipRows <- textRows[grep("chunked", textRows$transfer_encoding), ];
zipRows;
}
getUnCompressed <- function(textRows) {
uncomp <- textRows[textRows$content_length == textRows$response_body_len, ]
uncomp;
}
getCompressFailRows <- function(zipRows) {
# find entries with gzip in content_type
print("Finding Compress Fail")
compressFailRows <- zipRows[(zipRows$content_length > zipRows$response_body_len),];
compressFailRows;
}
httpData <- getHTTPData();
textRows <- getTextRows(httpData);
zipRows <- getZipRows(textRows)
chunkRows <- getChunkedRows(textRows)
uncompRows <- getUnCompressed(textRows)
compressFail <- getCompressFailRows(zipRows);
nrow(textRows)/nrow(httpData)
sum(textRows$connLen)/sum(httpData$connLen)
nrow(zipRows)/nrow(textRows)
sum(zipRows$connLen)/sum(textRows$connLen)
nrow(uncompRows)/nrow(textRows)
sum(uncompRows$connLen)/sum(textRows$connLen)
viewData(textRows)
median(textRows)
median(textRows$connLen)
quantile(textRows$connLen, c(0, 0.25, 0.5, 0.75, 1.0))
quantile(textRows$connLen, c(0, 0.25, 0.5, 0.75, 0.95, 1.0))
quantile(textRows$connLen, c(0, 0.25, 0.5, 0.75, 0.9, 0.95, 1.0))
